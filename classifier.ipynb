{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import os \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_number = 8\n",
    "vote_thr  = 0.5\n",
    "\n",
    "training_embeddings = '/data/omran/cities_data/embeddings/training/'\n",
    "input_image = np.load('/data/omran/cities_data/embeddings/test_10_images/London_2.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take one image embedding, folder of classes return the class \n",
    "\n",
    "def socre_one_image(img_embedding,image_class_name, databse_embeddings,vote_thr=0.1):\n",
    "    \n",
    "        \n",
    "    min_sum  = float('inf')\n",
    "    max_vote = 0\n",
    "    class_vote = ''\n",
    "    class_sum  = ''\n",
    "    \n",
    "    for filename in os.listdir(databse_embeddings):\n",
    "        \n",
    "        f = os.path.join(databse_embeddings, filename)\n",
    "        one_class_embedding = np.load(f) \n",
    "        \n",
    "        class_name = filename[:-6]\n",
    "        \n",
    "        sum_distance  = 0\n",
    "        vote = 0\n",
    "        \n",
    "       \n",
    "        for one_image in one_class_embedding:\n",
    "            \n",
    "            dist_cosine = distance.cosine(one_image, img_embedding)\n",
    "            sum_distance += dist_cosine\n",
    "            \n",
    "            if(dist_cosine< vote_thr):\n",
    "                vote+=1\n",
    "        \n",
    "         \n",
    "        dist_avge = (sum_distance/len(one_class_embedding))    \n",
    "        \n",
    "        #print(f'score on {class_name} : votes : {vote} distances : {dist_avge}' )        \n",
    "        if(vote > max_vote):\n",
    "            max_vote = vote\n",
    "            class_vote = class_name\n",
    "        \n",
    "        if(dist_avge < min_sum):\n",
    "            min_sum   = dist_avge\n",
    "            class_sum = class_name\n",
    "            \n",
    "    return class_vote,class_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_class = np.load('/data/omran/cities_data/embeddings/test_10_images/Roma_3.npy')\n",
    "databse_embeddings = '/data/omran/cities_data/embeddings/training/'\n",
    "\n",
    "for i in range(len(input_image_class)):\n",
    "    \n",
    "    print(f'Image number {i}')\n",
    "    class_vote,class_sum = socre_one_image(input_image_class[i],'London_2', databse_embeddings,vote_thr=0.1)\n",
    "    \n",
    "    \n",
    "    print(f'class_vote : {class_vote} and class_sum : {class_sum}')\n",
    "    print('#######################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class : Moscow, acc_vote 0.705, acc_sum 0.66\n",
      "class : London, acc_vote 0.595, acc_sum 0.48\n",
      "class : Shanghai, acc_vote 0.66, acc_sum 0.585\n",
      "class : Cairo, acc_vote 0.63, acc_sum 0.575\n",
      "class : Delhi, acc_vote 0.655, acc_sum 0.695\n",
      "class : New_york, acc_vote 0.435, acc_sum 0.23\n",
      "class : Rio_de_Janeiro, acc_vote 0.635, acc_sum 0.625\n",
      "class : Sydney, acc_vote 0.515, acc_sum 0.55\n",
      "class : Roma, acc_vote 0.62, acc_sum 0.6\n"
     ]
    }
   ],
   "source": [
    "test_folder        = '/data/omran/cities_data/embeddings/test/'\n",
    "#test_folder = '/data/omran/cities_data/embeddings/test_10_images'\n",
    "databse_embeddings = '/data/omran/cities_data/embeddings/test/'\n",
    "\n",
    "for filename in os.listdir(test_folder):\n",
    "    class_name = filename[:-6]\n",
    "    test_file = os.path.join(test_folder, filename)\n",
    "    \n",
    "    input_image_class = np.load(test_file)\n",
    "    \n",
    "    #print(class_name)\n",
    "    #print(len(input_image_class))\n",
    "    \n",
    "    counter_ture_vote  = 0 \n",
    "    counter_false_vote = 0\n",
    "\n",
    "    counter_ture_sum  = 0 \n",
    "    counter_false_sum = 0\n",
    "\n",
    "    for i in range(len(input_image_class)):\n",
    "        \n",
    "        \n",
    "        class_vote,class_sum = socre_one_image(input_image_class[i],class_name, databse_embeddings,vote_thr=0.1)\n",
    "        \n",
    "        if(class_name == class_vote):\n",
    "            counter_ture_vote+=1\n",
    "        else:\n",
    "            counter_false_vote+=1\n",
    "            \n",
    "        if(class_name==class_sum):\n",
    "            counter_ture_sum+=1\n",
    "        else:\n",
    "            counter_false_sum+=1 \n",
    "        \n",
    "         \n",
    "    #print(f'class : {class_name}, counter_ture_vote  {counter_ture_vote}, counter_ture_sum  {counter_ture_sum}')\n",
    "    #print(f'class : {class_name}, counter_false_vote {counter_false_vote}, counter_false_vote {counter_false_vote}')\n",
    "    print(f'class : {class_name}, acc_vote {counter_ture_vote/len(input_image_class)}, acc_sum {counter_ture_sum/len(input_image_class)}')\n",
    "        #print('#######################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/omran/cities_data/embeddings/training/Moscow_3.npy\n",
      "52\n",
      "0.31191801912769734\n",
      "/data/omran/cities_data/embeddings/training/London_2.npy\n",
      "65\n",
      "0.502682690249585\n",
      "/data/omran/cities_data/embeddings/training/Shanghai_7.npy\n",
      "5\n",
      "1.0333562104589147\n",
      "/data/omran/cities_data/embeddings/training/Cairo_0.npy\n",
      "1\n",
      "1.115622563593297\n",
      "/data/omran/cities_data/embeddings/training/Delhi_1.npy\n",
      "0\n",
      "1.1238494066038767\n",
      "/data/omran/cities_data/embeddings/training/New_york_4.npy\n",
      "12\n",
      "0.8248325676150239\n",
      "/data/omran/cities_data/embeddings/training/Rio_de_Janeiro_5.npy\n",
      "0\n",
      "1.2842847188710402\n",
      "/data/omran/cities_data/embeddings/training/Sydney_8.npy\n",
      "4\n",
      "1.2160585844467642\n",
      "/data/omran/cities_data/embeddings/training/Roma_6.npy\n",
      "2\n",
      "0.9338851570757833\n"
     ]
    }
   ],
   "source": [
    "training_embeddings = '/data/omran/cities_data/embeddings/training/'\n",
    "input_image = np.load('/data/omran/cities_data/embeddings/test_10_images/London_2.npy')\n",
    "\n",
    "for filename in os.listdir(training_embeddings):\n",
    "    f = os.path.join(training_embeddings, filename)\n",
    "    print(f)\n",
    "    sum = 0 \n",
    "    vote = 0\n",
    "    train_embed = np.load(f)\n",
    "    \n",
    "    #print(len(train_embed))\n",
    "\n",
    "    for one_image in train_embed:\n",
    "        \n",
    "        \n",
    "        \n",
    "        sum += (distance.cosine(one_image, input_image[im_number]))\n",
    "            \n",
    "        if(distance.cosine(one_image, input_image[im_number])< vote_thr):\n",
    "        \n",
    "\n",
    "            vote+=1\n",
    "            \n",
    "    print(vote)        \n",
    "    print(sum/len(train_embed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
